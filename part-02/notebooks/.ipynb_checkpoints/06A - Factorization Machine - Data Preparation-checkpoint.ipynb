{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "from fastFM import als\n",
    "from fastFM.datasets import make_user_item_regression\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06A - Factorization Machine - Data Preparation\n",
    "While factorization machines are immensely powerful in their ability to make use of additional features, these features must be processed such that they are interpretable by an FM. Specifically, categorical features needed to be one-hot encoded, and features consisting of lists of categories (like **genre**, where an item can be both a western and a comedy) need to be similarly binarized. To prevent an explosion in data size, these features are converted into sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "Import the training, cross-validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data_path = os.path.join('..', '..', 'data-2')\n",
    "splits_path = os.path.join(data_path,'splits')\n",
    "sparse_path = os.path.join(data_path,'sparse')\n",
    "columns = ['user','item','rating']\n",
    "\n",
    "with open(os.path.join(splits_path, 'train.df'), 'rb') as file_in:\n",
    "    train_df = pkl.load(file_in)\n",
    "    \n",
    "with open(os.path.join(splits_path, 'dev.df'), 'rb') as file_in:\n",
    "    cv_df = pkl.load(file_in)\n",
    "    \n",
    "with open(os.path.join(splits_path, 'test.df'), 'rb') as file_in:\n",
    "    test_df = pkl.load(file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional cleaning\n",
    "Scikit-learn's MultiLabelBinarizer converts between features consisting of lists of categories and a binary matrix indicating the presence of that category. In order for the MLB to function properly, all cells containing **None** must be converted to empty lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace 'None' with empty lists\n",
    "train_df['genres_imdb'] = train_df['genres_imdb'].apply(lambda x: [] if not x else x)\n",
    "cv_df['genres_imdb'] = cv_df['genres_imdb'].apply(lambda x: [] if not x else x)\n",
    "test_df['genres_imdb'] = test_df['genres_imdb'].apply(lambda x: [] if not x else x)\n",
    "\n",
    "train_df['studios_imdb'] = train_df['studios_imdb'].apply(lambda x: [] if not x else x)\n",
    "cv_df['studios_imdb'] = cv_df['studios_imdb'].apply(lambda x: [] if not x else x)\n",
    "test_df['studios_imdb'] = test_df['studios_imdb'].apply(lambda x: [] if not x else x)\n",
    "\n",
    "train_df['directors'] = train_df['directors'].apply(lambda x: [] if not x else x)\n",
    "cv_df['directors'] = cv_df['directors'].apply(lambda x: [] if not x else x)\n",
    "test_df['directors'] = test_df['directors'].apply(lambda x: [] if not x else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data\n",
    "The function below takes as input the three datasets, a target feature to be converted, a file path for saving, and a flag indicating whether the feature is to be one-hot encoded or converted using a MultiLabelBinarizer. In all cases, the data is converted to a sparse binary matrix in order to save space. All converted data is then stored into a dictionary (with 'train', cv', and 'test' as keys) so that the appropriate split can be easily accessed. Finally, the function saves the data into a specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_data(train, cv, test, features, filename, multi = False):\n",
    "    \n",
    "    # subset data\n",
    "    train = train[features]\n",
    "    cv = cv[features]\n",
    "    test = test[features]\n",
    "    \n",
    "    if multi:\n",
    "        # multi-label binarizing\n",
    "        mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "        X_train = mlb.fit_transform(train)\n",
    "        X_cv = mlb.transform(cv)\n",
    "        X_test = mlb.transform(test)\n",
    "        \n",
    "        data = dict(train=X_train, cv=X_cv, test=X_test, columns=mlb.classes_)\n",
    "        \n",
    "    else:\n",
    "        # one-hot encoding\n",
    "        X_train = pd.get_dummies(train)\n",
    "        X_train_empty = X_train.iloc[0:0, :] # empty dataframe for merging purposes later\n",
    "        X_train = csc_matrix(X_train)\n",
    "        \n",
    "        X_cv = pd.get_dummies(cv)\n",
    "        # re-order X_cv columns so they match with those of X_train and fill missing values with 0\n",
    "        X_cv = pd.concat([X_train_empty, X_cv], axis = 0).loc[:, X_train_empty.columns].fillna(0)\n",
    "        X_cv = csc_matrix(X_cv)\n",
    "        \n",
    "        X_test = pd.get_dummies(test)\n",
    "        # re-order X_cv columns so they match with those of X_train and fill missing values with 0\n",
    "        X_test = pd.concat([X_train_empty, X_test], axis = 0).loc[:, X_train_empty.columns].fillna(0)\n",
    "        X_test = csc_matrix(X_test)\n",
    "        \n",
    "        data = dict(train=X_train, cv=X_cv, test=X_test, columns=X_train_empty.columns)\n",
    "        \n",
    "    with open(os.path.join(sparse_path, filename + '.dict'), 'wb') as file_out:\n",
    "        pkl.dump(data, file_out)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we convert and save all features that need to be represented as sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_pretrained = True\n",
    "\n",
    "if use_pretrained:\n",
    "    with open(os.path.join(sparse_path, 'user-item.dict'), 'rb') as file_in:\n",
    "        user_item = pkl.load(file_in)\n",
    "else:\n",
    "    user_item = convert_data(train_df, cv_df, test_df, ['user','item'], 'user-item', multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = convert_data(train_df, cv_df, test_df, 'country', 'country', multi=True)\n",
    "language = convert_data(train_df, cv_df, test_df, 'language', 'language', multi=True)\n",
    "mpaa = convert_data(train_df, cv_df, test_df, 'mpaa_rating', 'mpaa', multi=False)\n",
    "type = convert_data(train_df, cv_df, test_df, 'type', 'type', multi=False)\n",
    "genres_imdb = convert_data(train_df, cv_df, test_df, 'genres_imdb', 'genres-imdb', multi=True)\n",
    "genres_amazon = convert_data(train_df, cv_df, test_df, 'genres_amazon', 'genres-amazon', multi=True)\n",
    "studios_imdb = convert_data(train_df, cv_df, test_df, 'studios_imdb', 'studios-imdb', multi=True)\n",
    "studios_amazon = convert_data(train_df, cv_df, test_df, 'studios_amazon', 'studios-amazon', multi=True)\n",
    "directors = convert_data(train_df, cv_df, test_df, 'directors', 'directors-imdb', multi=True)\n",
    "actors = convert_data(train_df, cv_df, test_df, 'actors', 'actors', multi=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
